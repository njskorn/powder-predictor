version: '3.8'

# Each service is a container
services:
  # PostgreSQL - Airflow's metadata database to track runs, task states, etc
  postgres:
    image: postgres:13
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    # Where data is stored
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 10s
      retries: 5
      start_period: 5s
    restart: always

  # Airflow Webserver - shows DAGs, displays logs, and provides a UI for monitoring, responsive
  airflow-webserver:
    image: apache/airflow:2.8.1-python3.11
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres/${POSTGRES_DB}
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
      AIRFLOW__WEBSERVER__EXPOSE_CONFIG: 'true'
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}          
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD} 
    volumes:
      - ./dags:/opt/airflow/dags
      - ./src:/opt/airflow/src
      - ./data:/opt/airflow/data
      - ./logs:/opt/airflow/logs
    ports:
      - "8080:8080"
    command: webserver
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always

  # Airflow Scheduler - schedules, watches and triggers tasks in DAGs, CPU intensive
  airflow-scheduler:
    image: apache/airflow:2.8.1-python3.11
    depends_on:
      postgres:
        condition: service_healthy
      airflow-webserver:
        condition: service_healthy
    environment:
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres/${POSTGRES_DB}
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}         
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD} 
    volumes:
      - ./dags:/opt/airflow/dags
      - ./src:/opt/airflow/src
      - ./data:/opt/airflow/data
      - ./logs:/opt/airflow/logs
    command: scheduler
    restart: always

  # MinIO - S3-compatible object storage
  minio:
    image: minio/minio:latest
    ports:
      - "9000:9000"      # API port
      - "9001:9001"      # Console/UI port
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
    volumes:
      - minio-data:/data
    command: server /data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
    restart: always

volumes:
  postgres-db-volume:
  minio-data: